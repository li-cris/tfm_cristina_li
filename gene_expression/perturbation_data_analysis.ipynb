{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analysis of Perturbations in Single-Cell RNA-Seq Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a `PertData` object to load and handle perturbation data.\n",
    "We specify that we want to load the `norman` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pertdata as pt\n",
    "\n",
    "norman = pt.PertData.from_repo(name=\"norman\", save_dir=\"data\")\n",
    "print(norman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and Preparation of Single-Cell RNA-Seq Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual perturbation data is stored in an [`AnnData`](https://anndata.readthedocs.io/en/latest/) object.\n",
    "`AnnData` is specifically designed for matrix-like data.\n",
    "By this we mean that we have $n$ observations, each of which can be represented as $d$-dimensional vectors, where each dimension corresponds to a variable or feature.\n",
    "Both the rows and columns of this $n \\times d$-matrix are special in the sense that they are indexed.\n",
    "For instance, in scRNA-seq data, each row corresponds to a cell with a barcode, and each column corresponds to a gene with a gene identifier.\n",
    "\n",
    "Here we show how to access the **gene expression matrix**, the **perturbations labels**, the **control labels**, and the **gene names**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norman)\n",
    "print(norman.adata)\n",
    "\n",
    "X = norman.adata.X\n",
    "y_pert = norman.adata.obs[\"condition\"]\n",
    "y_ctrl = norman.adata.obs[\"control\"]\n",
    "gene_names = norman.adata.var[\"gene_name\"]\n",
    "\n",
    "print(f\"X.shape={X.shape}\")\n",
    "print(f\"y_pert.shape={y_pert.shape}\")\n",
    "print(f\"y_ctrl.shape={y_ctrl.shape}\")\n",
    "print(f\"gene_names.shape={gene_names.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, in a perturbation dataset, we find $k$ cell lines.\n",
    "Usually, one cell line remains unperturbed, and the others are cultivated separately (with different perturbations, i.e., gene knockouts).\n",
    "The mRNA of usually a few thousand cells of each cell line is sequenced (using a single-cell RNA sequencing protocol), generating the $n$ $d$-dimensional gene expression profiles.\n",
    "In particular, perturbation labels are available (i.e., we know which genes were knocked out in each cell line).\n",
    "\n",
    "Before we can take a closer look at our data, we need to fix the perturbation labels, because they might be expressed ambiguously (e.g., single-gene perturbations can be expressed as `ctrl+<gene1>` or `<gene1>+ctrl`, falsely leading to two distinct labels for the perturbation of `<gene1>`).\n",
    "\n",
    "The `PertData` object already contains the fixed perturbation labels, which were computed during initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique perturbations (unfixed): {len(set(norman.adata.obs[\"condition\"]))}\")\n",
    "print(f\"Unique perturbations (fixed): {len(set(norman.adata.obs[\"condition_fixed\"]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we will work with single-gene perturbations only.\n",
    "Hence, we have to filter out double-gene perturbations.\n",
    "Double-gene perturbations can be identified by a `+` in the fixed perturbation labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_mask = ~norman.adata.obs[\"condition_fixed\"].str.contains(r\"\\+\")\n",
    "indexes_to_keep = filter_mask[filter_mask].index\n",
    "adata_single = norman.adata[indexes_to_keep].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adata_single)\n",
    "print(f\"Unique perturbations: {len(set(adata_single.obs['condition_fixed']))}\")\n",
    "print(\"Number of samples per condition:\")\n",
    "print(adata_single.obs[\"condition_fixed\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because gene expression data is very sparse, i.e., the expression is often not measured successfully or correctly, we will limit our experiment to the 128 genes with the highest variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of top genes to select\n",
    "d = 128\n",
    "\n",
    "# Compute the gene variances\n",
    "gene_variances = adata_single.X.toarray().var(axis=0)\n",
    "\n",
    "# Sort the gene variances in descending order and get the indexes of the top d genes\n",
    "sorted_indexes = gene_variances.argsort()[::-1]\n",
    "\n",
    "# Get the indexes of the top d genes\n",
    "top_gene_indexes = sorted_indexes[:d]\n",
    "\n",
    "# Get the gene names of the top d genes\n",
    "top_genes = adata_single.var[\"gene_name\"].iloc[top_gene_indexes]\n",
    "\n",
    "# Get the variances of the top d genes\n",
    "top_variances = gene_variances[top_gene_indexes]\n",
    "\n",
    "# Print the top d genes with the highest variances\n",
    "print(f\"Top {d} genes with highest variances:\")\n",
    "for gene, variance in zip(top_genes, top_variances):\n",
    "    print(f\"{gene:15}: {variance:.2f}\")\n",
    "\n",
    "# Create a new AnnData object with only the top d genes\n",
    "adata_single_top_genes = adata_single[:, top_gene_indexes].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an Autoencoder on Single-Cell RNA-Seq Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we prepare our data.\n",
    "\n",
    "Note that we shuffle the data in the `train_loader` but not in the `test_loader`.\n",
    "\n",
    "Shuffling the training data is a common practice to ensure that the model does not learn the order of the data.\n",
    "It helps in breaking correlations by preventing the model from learning any unintended patterns or correlations that might exist in the order of the training data.\n",
    "\n",
    "Shuffling is typically not used for the testing data because non-shuffled data ensures that the evaluation is consistent and reproducible.\n",
    "The model is tested on the same data in the same order each time, which is important for comparing performance across different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "# Convert the gene expression matrix to a PyTorch tensor\n",
    "X = torch.tensor(data=adata_single_top_genes.X.toarray(), dtype=torch.float32)\n",
    "\n",
    "# Create a PyTorch dataset\n",
    "dataset = TensorDataset(X, X)\n",
    "\n",
    "# Create train and test datasets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(\n",
    "    dataset=dataset, lengths=[train_size, test_size]\n",
    ")\n",
    "\n",
    "# Number of workers\n",
    "num_workers = 3  # Adjust based on the number of CPU cores\n",
    "\n",
    "# Create train and test data loaders\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "from autoencoder import Autoencoder\n",
    "\n",
    "# Get the number of features\n",
    "n_features = X.shape[1]\n",
    "print(f\"n_features={n_features}\")\n",
    "\n",
    "# Get the number of samples\n",
    "n_samples = X.shape[0]  # = len(train_dataset) + len(test_dataset) = len(dataset)\n",
    "print(f\"n_samples={n_samples}\")\n",
    "\n",
    "# Create the autoencoder\n",
    "autoencoder = Autoencoder(in_features=n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "# Initialize the CSV logger\n",
    "logger = CSVLogger(save_dir=\"lightning_logs\", name=\"ae_experiment\")\n",
    "\n",
    "# Train the autoencoder\n",
    "trainer = pl.Trainer(max_epochs=4, logger=logger)\n",
    "trainer.fit(model=autoencoder, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the autoencoder\n",
    "trainer.test(model=autoencoder, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_train_loss(logfile: str) -> None:\n",
    "    print(f\"logfile={logfile}\")\n",
    "    log = pd.read_csv(filepath_or_buffer=logfile)\n",
    "    plt.plot(log[\"step\"], log[\"train_loss\"])\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Train Loss\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Construct the path to the most recent version directory\n",
    "most_recent_metrics_file = os.path.join(\n",
    "    logger.save_dir, logger.name, f\"version_{logger.version}\", \"metrics.csv\"\n",
    ")\n",
    "\n",
    "# Plot the training loss\n",
    "plot_train_loss(logfile=most_recent_metrics_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
