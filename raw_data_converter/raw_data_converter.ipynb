{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Download for Transmet\n",
    "\n",
    "This script downloads the original datasets to be used with Transmet.\n",
    "\n",
    "Three datasets are available: `Norman`, `Dixit`, and `Adamson`.\n",
    "\n",
    "Each dataset is generated from the original data, with cells filtered so that only those selected by GEARS are included.\n",
    "\n",
    "For each dataset, the output is a `.h5ad` file that contains the gene expression matrix for each sample, along with the condition (i.e., which gene(s) were perturbed).\n",
    "\n",
    "The datasets are saved in `.h5ad` format in the `../datasets/[dataset_name]/processed` folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import shutil\n",
    "import anndata as ad\n",
    "\n",
    "sys.path.append(\"../gene_expression\")\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract_tar(tar_link, dir_name):\n",
    "    os.system(\"mkdir -p \" + dir_name)\n",
    "    utils.download_file(tar_link, dir_name + \"/data.tar\")\n",
    "    utils.extract_tar(dir_name + \"/data.tar\", dir_name)\n",
    "\n",
    "\n",
    "def organize_adamson_experiments(root_folder):\n",
    "    \"\"\"\n",
    "    Organizes the folder by creating a new directory for each experiment and moving the respective files\n",
    "    into the new directories with updated names.\n",
    "\n",
    "    Args:\n",
    "    - root_folder (str): Path to the folder containing the experiment files.\n",
    "    \"\"\"\n",
    "    # List all files in the root folder\n",
    "    files = os.listdir(root_folder)\n",
    "\n",
    "    # Iterate through the files to identify unique experiments\n",
    "    experiments = set()\n",
    "    for file in files:\n",
    "        if file.startswith(\"GSM\"):\n",
    "            experiment = \"_\".join(\n",
    "                file.split(\"_\")[:2]\n",
    "            )  # Extract experiment identifier (e.g., GSM2406681_10X010)\n",
    "            experiments.add(experiment)\n",
    "\n",
    "    # For each experiment, create a folder and move respective files\n",
    "    for experiment in experiments:\n",
    "        # Create a new folder for the experiment\n",
    "        experiment_dir = os.path.join(root_folder, experiment)\n",
    "        os.makedirs(experiment_dir, exist_ok=True)\n",
    "\n",
    "        # Define the new file names\n",
    "        new_file_names = {\n",
    "            \"barcodes\": \"raw_barcodes.tsv.gz\",\n",
    "            \"matrix\": \"raw_matrix.mtx.gz\",\n",
    "            \"genes\": \"raw_features.tsv.gz\",\n",
    "            \"cell_identities\": \"raw_cell_identities.csv.gz\",\n",
    "        }\n",
    "\n",
    "        # Move and rename the respective files\n",
    "        for file_type, new_name in new_file_names.items():\n",
    "            for file in files:\n",
    "                if file.startswith(experiment) and file_type in file:\n",
    "                    old_path = os.path.join(root_folder, file)\n",
    "                    new_path = os.path.join(experiment_dir, new_name)\n",
    "                    shutil.move(old_path, new_path)\n",
    "                    print(f\"Moved and renamed {file} to {new_path}\")\n",
    "\n",
    "    print(\"Folder organization complete.\")\n",
    "\n",
    "\n",
    "# Function to load a single dataset and return an AnnData object\n",
    "def load_dixit_dataset(experiment_dir_root):\n",
    "    \"\"\"\n",
    "    Load a dataset from MTX, gene, and cell files into an AnnData object.\n",
    "\n",
    "    This function reads an expression matrix in MTX format, gene names, and cell names,\n",
    "    and constructs an AnnData object with the appropriate annotations.\n",
    "\n",
    "    Parameters:\n",
    "    mtx_file (str): Path to the MTX file containing the expression matrix.\n",
    "    gene_file (str): Path to the CSV file containing gene names and IDs.\n",
    "    cell_file (str): Path to the CSV file containing cell names.\n",
    "\n",
    "    Returns:\n",
    "    AnnData: An AnnData object containing the expression matrix with gene and cell annotations.\n",
    "    \"\"\"\n",
    "    mtx_file = experiment_dir_root + \".mtx.txt.gz\"\n",
    "    gene_file = experiment_dir_root + \"_genenames.csv.gz\"\n",
    "    cell_file = experiment_dir_root + \"_cellnames.csv.gz\"\n",
    "\n",
    "    # Load the expression matrix (MTX format)\n",
    "    adata = sc.read_mtx(mtx_file).transpose()\n",
    "\n",
    "    # Load gene names and gene IDs (using only the gene_id part)\n",
    "    gene_names = pd.read_csv(gene_file, index_col=0)\n",
    "    gene_ids = gene_names[\"0\"].str.split(\"_\").str[0]  # Extract only the gene IDs\n",
    "    adata.var_names = gene_ids\n",
    "\n",
    "    # Load cell names and set them in the AnnData object\n",
    "    cell_names = pd.read_csv(cell_file, index_col=0)\n",
    "    cell_ids = cell_names[\"0\"]\n",
    "    adata.obs_names = cell_ids\n",
    "\n",
    "    return adata\n",
    "\n",
    "\n",
    "def modify_features_file(genes_path):\n",
    "    \"\"\"Modifies the features file to append 'Gene Expression' if not already present.\"\"\"\n",
    "    temp_file_path = \"temp_genes.tsv.gz\"\n",
    "\n",
    "    with gzip.open(genes_path, \"rt\") as f_in:\n",
    "        lines = f_in.readlines()\n",
    "\n",
    "    if not lines[0].strip().endswith(\"Gene Expression\"):\n",
    "        with gzip.open(temp_file_path, \"wt\") as f_out:\n",
    "            for line in lines:\n",
    "                line = line.strip() + \"\\tGene Expression\\n\"\n",
    "                f_out.write(line)\n",
    "        os.replace(temp_file_path, genes_path)\n",
    "        print(f\"Modified {genes_path} to add 'Gene Expression'.\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"'Gene Expression' already present in {genes_path}, no modification needed.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def filter_barcodes_and_add_condition(adata, barcode_file, verbose=False):\n",
    "    \"\"\"\n",
    "    Filters the AnnData object to keep only cells present in the barcode-to-cell-type mapping file and adds condition info.\n",
    "    Also prints the barcodes that are in the barcode file but not found in the AnnData object.\n",
    "\n",
    "    Args:\n",
    "    - adata (AnnData): AnnData object containing the gene expression data.\n",
    "    - barcode_file (str): Path to the barcode file containing cell barcodes and their corresponding conditions.\n",
    "    \"\"\"\n",
    "    # Load barcode file\n",
    "    barcode_df = pd.read_csv(barcode_file, sep=\",\")\n",
    "    barcodes_to_keep = barcode_df[\"cell_barcode\"].values\n",
    "\n",
    "    if verbose:\n",
    "        # Find barcodes in the file but not in adata\n",
    "        missing_barcodes = set(barcodes_to_keep) - set(adata.obs_names)\n",
    "        if missing_barcodes:\n",
    "            print(f\"Barcodes not found in AnnData: {len(missing_barcodes)}\")\n",
    "            print(missing_barcodes)\n",
    "        else:\n",
    "            print(\"All barcodes from the file are present in the AnnData object.\")\n",
    "\n",
    "    # Filter adata based on the barcodes present in the barcode file\n",
    "    adata_filtered = adata[adata.obs_names.isin(barcodes_to_keep)].copy()\n",
    "\n",
    "    # Add condition information to the filtered adata\n",
    "    barcode_dict = dict(zip(barcode_df[\"cell_barcode\"], barcode_df[\"condition\"]))\n",
    "    adata_filtered.obs[\"condition\"] = adata_filtered.obs_names.map(barcode_dict)\n",
    "\n",
    "    print(f\"Filtered AnnData to {adata_filtered.shape[0]} cells based on barcodes.\")\n",
    "    return adata_filtered\n",
    "\n",
    "\n",
    "def save_h5ad(adata, output_path):\n",
    "    \"\"\"Saves the AnnData object to an HDF5 file.\"\"\"\n",
    "    adata.write_h5ad(output_path)\n",
    "    print(f\"AnnData object saved to {output_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data directories\n",
    "\n",
    "All the data is stored in the `data` directory. There are two subdirectories: `raw` and `processed`. The `raw` directory stores the raw data files as uploaded to the NCBI original paper dataset. The `processed` directory stores, for each perturbed dataset, an `h5ad` file that contains the raw counts and the normalized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory for the raw data\n",
    "datasets_dir = \"../datasets\"\n",
    "os.system(\"mkdir -p \" + datasets_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Norman\n",
    "\n",
    "The original dataset from Norman et al., titled \"Exploring genetic interaction manifolds constructed from rich single-cell phenotypes,\" is available at [GEO: GSE133344](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE133344).\n",
    "\n",
    "First, we create the directories where the data will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norman directory\n",
    "norman_dataset_dir = datasets_dir + \"/norman\"\n",
    "os.system(\"mkdir -p \" + norman_dataset_dir)\n",
    "\n",
    "# Norman raw data directory\n",
    "norman_raw_dir = norman_dataset_dir + \"/raw\"\n",
    "os.system(\"mkdir -p \" + norman_raw_dir)\n",
    "\n",
    "# Norman processed data directory\n",
    "norman_processed_dir = norman_dataset_dir + \"/processed\"\n",
    "os.system(\"mkdir -p \" + norman_processed_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the Norman raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Norman dataset\n",
    "if not os.path.exists(norman_raw_dir + \"/raw_barcodes.tsv.gz\"):\n",
    "    utils.download_file(\n",
    "        \"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE133344&format=file&file=GSE133344%5Fraw%5Fbarcodes%2Etsv%2Egz\",\n",
    "        norman_raw_dir + \"/raw_barcodes.tsv.gz\",\n",
    "    )\n",
    "if not os.path.exists(norman_raw_dir + \"/raw_cell_identities.csv.gz\"):\n",
    "    utils.download_file(\n",
    "        \"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE133344&format=file&file=GSE133344%5Fraw%5Fcell%5Fidentities%2Ecsv%2Egz\",\n",
    "        norman_raw_dir + \"/raw_cell_identities.csv.gz\",\n",
    "    )\n",
    "if not os.path.exists(norman_raw_dir + \"/raw_features.tsv.gz\"):\n",
    "    utils.download_file(\n",
    "        \"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE133344&format=file&file=GSE133344%5Fraw%5Fgenes%2Etsv%2Egz\",\n",
    "        norman_raw_dir + \"/raw_features.tsv.gz\",\n",
    "    )\n",
    "if not os.path.exists(norman_raw_dir + \"/raw_matrix.mtx.gz\"):\n",
    "    utils.download_file(\n",
    "        \"https://ftp.ncbi.nlm.nih.gov/geo/series/GSE133nnn/GSE133344/suppl/GSE133344%5Fraw%5Fmatrix%2Emtx%2Egz\",\n",
    "        norman_raw_dir + \"/raw_matrix.mtx.gz\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features.tsv.gz file needs to have a third column with the value \"Gene Expression\" to be loaded with sc.read_10x_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modify_features_file(norman_raw_dir + \"/raw_features.tsv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a prefix for the files in the Norman dataset. This is needed to run sc.read_10x_mtx method from scanpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "norman_prefix = \"raw_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Norman data into an AnnData object. This may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_10x_mtx(\n",
    "    norman_raw_dir, var_names=\"gene_ids\", cache=False, prefix=norman_prefix\n",
    ")\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the Anne data object to keep only cells present in the gears barcodes file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = filter_barcodes_and_add_condition(\n",
    "    adata, \"../data/gears_barcodes/norman_barcodes.csv\", verbose=True\n",
    ")\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the adata into a .h5ad file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_h5ad(adata, norman_processed_dir + \"/norman.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dixit\n",
    "\n",
    "A. Dixit et al. “Perturb-Seq: Dissecting Molecular Circuits with Scalable Single-Cell RNA Profiling\n",
    "of Pooled Genetic Screens”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frist, we create the directories where de data will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dixit directory\n",
    "dixit_dataset_dir = datasets_dir + \"/dixit\"\n",
    "os.system(\"mkdir -p \" + dixit_dataset_dir)\n",
    "\n",
    "# Dixit raw data directory\n",
    "dixit_raw_dir = dixit_dataset_dir + \"/raw\"\n",
    "os.system(\"mkdir -p \" + dixit_raw_dir)\n",
    "\n",
    "# Dixit processed data directory\n",
    "dixit_processed_dir = dixit_dataset_dir + \"/processed\"\n",
    "os.system(\"mkdir -p \" + dixit_processed_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data. In this case, the data is in a `.tar` format and should be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dixit_tar_link = \"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE90063&format=file\"\n",
    "# Use the function for Dixit dataset\n",
    "download_and_extract_tar(dixit_tar_link, dixit_raw_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several experiments in the Dixit dataset, however, GEARS only uses two of the experiments, whose files have the following prefix:\n",
    "1. GSM2396858_k562_tfs_7\n",
    "2. GSM2396861_k562_ccycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first experiment (TFs)\n",
    "experiment1 = \"GSM2396858_k562_tfs_7\"\n",
    "adata1 = load_dixit_dataset(dixit_raw_dir + \"/\" + experiment1)\n",
    "\n",
    "# Load the second experiment (Cell Cycle)\n",
    "experiment2 = \"GSM2396861_k562_ccycle\"\n",
    "adata2 = load_dixit_dataset(dixit_raw_dir + \"/\" + experiment2)\n",
    "\n",
    "# Concatenate the two AnnData objects, ensuring unique observations\n",
    "adata_combined = ad.concat([adata1, adata2], axis=0, join=\"outer\", index_unique=None)\n",
    "\n",
    "# Output the combined AnnData object\n",
    "print(adata_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the Anne data to keep only cells present in the gears barcodes file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = filter_barcodes_and_add_condition(\n",
    "    adata_combined, \"gears_barcodes/dixit_barcodes.csv\", verbose=True\n",
    ")\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that 89 barcodes which are used in GEARS data are not found in our repository.\n",
    "\n",
    "Output the adata into a .h5ad file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_h5ad(adata, dixit_processed_dir + \"/dixit.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adamson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Adamson et al. “A Multiplexed Single-Cell CRISPR Screening Platform Enables Systematic\n",
    "Dissection of the Unfolded Protein Response”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create the directories where de data will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adamson directory\n",
    "adamson_dataset_dir = datasets_dir + \"/adamson\"\n",
    "os.system(\"mkdir -p \" + adamson_dataset_dir)\n",
    "\n",
    "# Adamson raw data directory\n",
    "adamson_raw_dir = adamson_dataset_dir + \"/raw\"\n",
    "os.system(\"mkdir -p \" + adamson_raw_dir)\n",
    "\n",
    "# Adamson processed data directory\n",
    "adamson_processed_dir = adamson_dataset_dir + \"/processed\"\n",
    "os.system(\"mkdir -p \" + adamson_processed_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data in .tar format and extract it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adamson_tar_link = \"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE90546&format=file\"  # Use the function for Adamson dataset\n",
    "download_and_extract_tar(adamson_tar_link, adamson_raw_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adamson 10x genomics output data needs to be organized in different folders to be loaded using the sc.read_10x function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize the Adamson directory\n",
    "organize_adamson_experiments(adamson_raw_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the experiments need to add a column with Gene expression for sc.read_10x function to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each directory of an experiment in adamson_raw_dir run modify_features_file\n",
    "for dir_name in os.listdir(adamson_raw_dir):\n",
    "    dir_path = os.path.join(adamson_raw_dir, dir_name)\n",
    "    if os.path.isdir(dir_path):\n",
    "        modify_features_file(dir_path + \"/raw_features.tsv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a prefix for adamson experiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "adamson_prefix = \"raw_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the experiments Anne objects and combine them into one. This may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the datasets\n",
    "adata1 = sc.read_10x_mtx(\n",
    "    adamson_raw_dir + \"/GSM2406675_10X001\",\n",
    "    var_names=\"gene_ids\",\n",
    "    cache=False,\n",
    "    prefix=adamson_prefix,\n",
    ")\n",
    "\n",
    "adata2 = sc.read_10x_mtx(\n",
    "    adamson_raw_dir + \"/GSM2406677_10X005\",\n",
    "    var_names=\"gene_ids\",\n",
    "    cache=False,\n",
    "    prefix=adamson_prefix,\n",
    ")\n",
    "\n",
    "adata3 = sc.read_10x_mtx(\n",
    "    adamson_raw_dir + \"/GSM2406681_10X010\",\n",
    "    var_names=\"gene_ids\",\n",
    "    cache=False,\n",
    "    prefix=adamson_prefix,\n",
    ")\n",
    "\n",
    "# Concatenate the datasets with unique observations\n",
    "adata_combined = ad.concat(\n",
    "    [adata1, adata2, adata3], axis=0, join=\"outer\", index_unique=None\n",
    ")  # Use \"-\" to make obs_names unique\n",
    "\n",
    "# Output the combined AnnData object\n",
    "print(adata_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the Anne data to keep only cells present in the gears barcodes file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = filter_barcodes_and_add_condition(\n",
    "    adata_combined, \"../data/gears_barcodes/adamson_barcodes.csv\", verbose=True\n",
    ")\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that 172 barcodes which are used in GEARS data are not found in our repository.\n",
    "\n",
    "Output the adata into a .h5ad file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_h5ad(adata, adamson_processed_dir + \"/adamson.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replogle et al. 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "replogle_raw_h5ad_link = \"https://plus.figshare.com/ndownloader/files/35775606\"\n",
    "\n",
    "# TODO: Download the Replogle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
