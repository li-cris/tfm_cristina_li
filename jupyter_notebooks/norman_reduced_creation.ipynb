{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae4bc8a",
   "metadata": {},
   "source": [
    "# Annotated Data changes for all tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62fad93",
   "metadata": {},
   "source": [
    "This Notebook walks through the general process of .obs and .var differences between tools (SENA, GEARS, scGPT and lgem model). Each has some key differences in how some variables in their Annotated Data is named. Some tools (scGPT and lgem) only works with valid samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import os\n",
    "\n",
    "from gears import PertData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b0df07",
   "metadata": {},
   "source": [
    "### Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "35088776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/tfm/SENA/data/Norman2019_reduced.h5ad\n"
     ]
    }
   ],
   "source": [
    "# For loading 'raw data'\n",
    "univ_path = '/workspace/tfm/SENA/data'\n",
    "data_name = 'Norman2019_reduced.h5ad'\n",
    "filepath = os.path.join(univ_path, data_name)\n",
    "print(filepath)\n",
    "\n",
    "# For saving data processed by GEARS PertData data handler\n",
    "# Save data in common directory\n",
    "data_savedir = '/workspace/tfm/cris_test/data'\n",
    "name_new_dataset = 'norman_reduced'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0aacd2",
   "metadata": {},
   "source": [
    "### Loading and data changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7380ca96",
   "metadata": {},
   "source": [
    "AnnData requirements:\n",
    "- (SENA) adata.obs['guide_ids]: Condition of each sample. **'ctrl', 'GeneA', 'GeneA,GeneB'**\n",
    "- (SENA) adata.var['gene_symbols']\n",
    "- (GEARS) adata.var['gene_name'] = adata.var['gene_symbols']\n",
    "- (GEARS) adata.obs['condition']: Condition of each sample. **'ctrl' 'ctrl+geneA' 'geneA+ctrl' 'geneA+geneB'**\n",
    "- (lgem) adata.obs['condition_fixed]: Condition of each sample. **'ctrl' 'geneA' 'geneA+geneB'** \n",
    "- (scGPT) adata.var['gene_name'] = adata.var['gene_symbols']\n",
    "</br>\n",
    "\n",
    "ATTENTION: Depending on the version of pickler, there might be issues with pickle loading. scGPT uses an older version. Since I couldn't find an easier way to solve this, you should recreate the dataset inside the docker space for scGPT. SENA is the only one that doesn't use GEARS module's data handler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beb86712",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d266ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 11850 × 5000\n",
       "    obs: 'guide_identity', 'read_count', 'UMI_count', 'gemgroup', 'good_coverage', 'number_of_cells', 'guide_ids', 'guide_merged', 'split', 'batch', 'condition', 'cell_type', 'dose_val', 'control', 'drug_dose_name', 'cov_drug_dose_name'\n",
       "    var: 'gene_symbols', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
       "    uns: 'rank_genes_groups', 'rank_genes_groups_cov'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d537a226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "CCCTCCTAGAGGTAGA-3-0-0    CEBPE,RUNX1T1\n",
       "ATCTACTGTTATGCGT-1-0-0             DLX2\n",
       "CGGACTGGTTGACGTT-6-0-0            ZBTB1\n",
       "AACTTTCGTACGAAAT-5-0-0          AHR,FEV\n",
       "GGACAGAGTGGTCCGT-2-0-0       CNN1,MAPK1\n",
       "                              ...      \n",
       "ACATCAGCATACTCTT-2-1-1                 \n",
       "ATTGGTGTCAGCGATT-2-1-1                 \n",
       "CGCCAAGGTAGCTCCG-6-1-1                 \n",
       "CTAAGACTCCTGTACC-1-1-1                 \n",
       "GTATCTTGTCTACCTC-2-1-1                 \n",
       "Name: guide_ids, Length: 11850, dtype: category\n",
       "Categories (237, object): ['', 'AHR', 'AHR,FEV', 'AHR,KLF1', ..., 'ZBTB10', 'ZBTB25', 'ZC3HAV1', 'ZNF318']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs['guide_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da05cb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_name\n",
    "adata.var['gene_name'] = adata.var['gene_symbols']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99402a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition_fixed. Works with norman datastet\n",
    "splitting = adata.obs['condition'].str.split('+')\n",
    "for i in range(len(splitting)):\n",
    "    if len(splitting[i]) == 2:\n",
    "        if 'ctrl' in splitting[i]:\n",
    "            splitting[i].remove('ctrl')\n",
    "\n",
    "join_names = splitting.apply(lambda x: '+'.join(sorted(x))) # Makes sure that order is the same\n",
    "adata.obs['condition_fixed'] = join_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55926234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284\n",
      "237\n",
      "237\n"
     ]
    }
   ],
   "source": [
    "# Check that condition_fixed and guide_ids have same length\n",
    "print(len(adata.obs['condition'].unique()))\n",
    "print(len(adata.obs['condition_fixed'].unique()))\n",
    "print(len(adata.obs['guide_ids'].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf26d4d4",
   "metadata": {},
   "source": [
    "## Creating Gears Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441b47ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Found local copy...\n",
      "Creating pyg object for each cell in the data...\n",
      "Creating dataset file...\n",
      " 21%|████████████████████████▎                                                                                        | 61/284 [00:19<01:05,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LYL1+IER5L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████████████▍                                                                                 | 79/284 [00:27<02:43,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IER5L+ctrl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████████████████████████████████████▏                                           | 173/284 [01:16<00:39,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KIAA1804+ctrl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎          | 257/284 [01:41<00:06,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctrl+IER5L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 284/284 [01:47<00:00,  2.64it/s]\n",
      "Done!\n",
      "Saving new dataset pyg object at /workspace/tfm/cris_test/data/norman_reduced/data_pyg/cell_graphs.pkl\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# GEARS pertdata pickle creation\n",
    "# Can take around 10-15 minutes for the usual, non-reduced datafiles.\n",
    "pert_data = PertData(data_savedir) # specific saved folder\n",
    "pert_data.new_data_process(dataset_name = name_new_dataset, adata = adata) # specific dataset name and adata object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80828a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "These perturbations are not in the GO graph and their perturbation can thus not be predicted\n",
      "['LYL1+IER5L' 'IER5L+ctrl' 'KIAA1804+ctrl' 'ctrl+IER5L']\n",
      "Local copy of pyg dataset is detected. Loading...\n",
      "Done!\n",
      "Creating new splits....\n",
      "Saving new splits at /workspace/tfm/cris_test/data/norman_reduced/splits/norman_reduced_simulation_42_0.75.pkl\n",
      "Simulation split test composition:\n",
      "combo_seen0:5\n",
      "combo_seen1:57\n",
      "combo_seen2:17\n",
      "unseen_single:37\n",
      "Done!\n",
      "Creating dataloaders....\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# GEARS pertdata laoding\n",
    "# Mostly to check that dataloader works without any problems\n",
    "pert_data.load(data_path = os.path.join(data_savedir, name_new_dataset)) # load the processed data, the path is saved folder + dataset_name\n",
    "pert_data.prepare_split(split = 'simulation', seed = 42) # get data split with seed\n",
    "pert_data.get_dataloader(batch_size = 32, test_batch_size = 128) # prepare data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605d3a77",
   "metadata": {},
   "source": [
    "#### Warning: PertData removes some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de3c15fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 11700 × 5000\n",
       "    obs: 'guide_identity', 'read_count', 'UMI_count', 'gemgroup', 'good_coverage', 'number_of_cells', 'guide_ids', 'guide_merged', 'split', 'batch', 'condition', 'cell_type', 'dose_val', 'control', 'drug_dose_name', 'cov_drug_dose_name', 'condition_name', 'condition_fixed'\n",
       "    var: 'gene_symbols', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'gene_name'\n",
       "    uns: 'non_dropout_gene_idx', 'non_zeros_gene_idx', 'rank_genes_groups', 'rank_genes_groups_cov', 'rank_genes_groups_cov_all', 'top_non_dropout_de_20', 'top_non_zero_de_20'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pert_data.adata # PertData removes some samples that aren't in the GO graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2d70458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 11850 × 5000\n",
       "    obs: 'guide_identity', 'read_count', 'UMI_count', 'gemgroup', 'good_coverage', 'number_of_cells', 'guide_ids', 'guide_merged', 'split', 'batch', 'condition', 'cell_type', 'dose_val', 'control', 'drug_dose_name', 'cov_drug_dose_name', 'condition_name', 'condition_fixed'\n",
       "    var: 'gene_symbols', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'gene_name'\n",
       "    uns: 'rank_genes_groups', 'rank_genes_groups_cov', 'rank_genes_groups_cov_all', 'top_non_dropout_de_20', 'non_dropout_gene_idx', 'non_zeros_gene_idx', 'top_non_zero_de_20'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ffa3fa",
   "metadata": {},
   "source": [
    "#### Data handling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d810751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_data(adata = None, dataset_name: str = \"norman\"):\n",
    "    \"\"\"Get the single perturbation dataset, double perturbation dataset and control dataset from the given AnnData object as well as list of single perturbations.\"\"\"\n",
    "    if \"norman\" in dataset_name.lower():\n",
    "       # Preprocessing dataset\n",
    "        splitting = adata.obs['condition'].str.split('+')\n",
    "        for i in range(len(splitting)):\n",
    "            if len(splitting[i]) == 2:\n",
    "                if 'ctrl' in splitting[i]:\n",
    "                    splitting[i].remove('ctrl')\n",
    "\n",
    "        join_names = splitting.apply(lambda x: '+'.join(sorted(x))) # Makes sure that order is the same\n",
    "        adata.obs['condition_fixed'] = join_names\n",
    "\n",
    "        # Keeping only single perturbations\n",
    "        filter_mask = ~adata.obs[\"condition_fixed\"].str.contains(r\"\\+\") # mask for those NOT containing +\n",
    "        indexes_to_keep = filter_mask[filter_mask].index # mask that finds indeces in norman adata that aren't double perturbations\n",
    "\n",
    "        # Dataset with single perts\n",
    "        adata_single = adata[indexes_to_keep].copy()\n",
    "        adata_single = adata_single[adata_single.obs['condition_fixed']!='ctrl']\n",
    "\n",
    "        # Dataset with double perts\n",
    "        adata_double = adata[~adata.obs['condition_fixed'].isin(adata_single.obs['condition_fixed'])].copy()\n",
    "        adata_double = adata_double[adata_double.obs['condition_fixed']!='ctrl']\n",
    "\n",
    "        # Ctrl expression\n",
    "        adata_ctrl = adata[adata.obs['condition_fixed']=='ctrl'].copy()\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"Dataset not implemented yet.\")\n",
    "\n",
    "    return adata_single, adata_double, adata_ctrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0aea9d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_genes(adata = None, dataset_name: str = \"norman\"):\n",
    "    \"\"\"Get adata with perts found in genes (features) and return list of perts and genes.\"\"\"\n",
    "    if \"norman\" in dataset_name.lower():\n",
    "        all_perts = adata.obs['condition_fixed'].values\n",
    "        genes = set(adata.var['gene_symbols'].values)\n",
    "\n",
    "        # Makes function work even with double perts\n",
    "        def valid_pert(pert):\n",
    "            pair_genes = pert.split(\"+\")\n",
    "            return all(gene in genes for gene in pair_genes)\n",
    "\n",
    "        valid_perts = [p for p in all_perts if valid_pert(p)]\n",
    "        adata_common = adata[adata.obs[\"condition_fixed\"].isin(valid_perts)].copy() # Only keep perts that are in features\n",
    "        perts = adata_common.obs[\"condition_fixed\"].unique().tolist()\n",
    "    else:\n",
    "        print(\"Dataset not implemented yet.\")\n",
    "    return all_perts, perts, list(genes), adata_common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8274c998",
   "metadata": {},
   "source": [
    "#### Samples with gene perturbations that are found in features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c49809f",
   "metadata": {},
   "source": [
    "lgem and scGPT requires that its perturbed samples are found in the list of features (adata.var['gene_symbols']). adata_common can also be saved in its own with GEARS data_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e835466",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_perts, perts, genes, adata_common = get_common_genes(pert_data.adata, 'norman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "23ac7d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 6250 × 5000\n",
       "    obs: 'guide_identity', 'read_count', 'UMI_count', 'gemgroup', 'good_coverage', 'number_of_cells', 'guide_ids', 'guide_merged', 'split', 'batch', 'condition', 'cell_type', 'dose_val', 'control', 'drug_dose_name', 'cov_drug_dose_name', 'condition_name', 'condition_fixed'\n",
       "    var: 'gene_symbols', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'gene_name'\n",
       "    uns: 'non_dropout_gene_idx', 'non_zeros_gene_idx', 'rank_genes_groups', 'rank_genes_groups_cov', 'rank_genes_groups_cov_all', 'top_non_dropout_de_20', 'top_non_zero_de_20'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_common "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
